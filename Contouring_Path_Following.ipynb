{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use traitlets and widgets to display the image in Jupyter Notebook\n",
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "#use opencv to covert the depth image to RGB image for displaying purpose\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from RobotClass import Robot\n",
    "\n",
    "#using realsense to capture the color and depth image\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    #this changing of this value will be captured by traitlets\n",
    "    value = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "        \n",
    "        #configure the color and depth sensor\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.configuration = rs.config()  \n",
    "        \n",
    "        #set resolution for the color camera\n",
    "        self.color_width = 640\n",
    "        self.color_height = 480\n",
    "        self.color_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.color, self.color_width, self.color_height, rs.format.bgr8, self.color_fps)\n",
    "\n",
    "        #set resolution for the depth camera\n",
    "        self.depth_width = 640\n",
    "        self.depth_height = 480\n",
    "        self.depth_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.depth, self.depth_width, self.depth_height, rs.format.z16, self.depth_fps)\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "        \n",
    "        #start the RGBD sensor\n",
    "        self.pipeline.start(self.configuration)\n",
    "        self.pipeline_started = True\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "\n",
    "        #start capture the first color image\n",
    "        color_frame = frames.get_color_frame()   \n",
    "        image = np.asanyarray(color_frame.get_data())\n",
    "        self.value = image\n",
    "\n",
    "        #start capture the first depth image\n",
    "        depth_frame = frames.get_depth_frame()           \n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        self.depth_value = depth_colormap   \n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            frames = self.pipeline.wait_for_frames() #receive data from RGBD sensor\n",
    "            \n",
    "            color_frame = frames.get_color_frame() #get the color image\n",
    "            image = np.asanyarray(color_frame.get_data()) #convert color image to numpy array\n",
    "            self.value = image #assign the numpy array image to the color_value variable \n",
    "\n",
    "            depth_frame = frames.get_depth_frame() #get the depth image           \n",
    "            depth_image = np.asanyarray(depth_frame.get_data()) #convert depth data to numpy array\n",
    "            #conver depth data to BGR image for displaying purpose\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            self.depth_value = depth_colormap #assign the color BGR image to the depth value\n",
    "    \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7a96ac40fb462f88e887d089b0cdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='300', width='300')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from drivers import PCA9685, Motor\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "\n",
    "# Function to convert BGR image to JPEG for displaying in the widget\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "def line_detection(image, lower_color, upper_color):\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    " \n",
    "\n",
    "    if len(contours) > 0:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        moment = cv2.moments(largest_contour)\n",
    "\n",
    "        if moment[\"m00\"] != 0:\n",
    "            cx = int(moment[\"m10\"] / moment[\"m00\"])\n",
    "            cy = int(moment[\"m01\"] / moment[\"m00\"])\n",
    "            return (True, cx, cy, largest_contour)\n",
    "\n",
    "    return (False, None, None, None)\n",
    "\n",
    " \n",
    "\n",
    "def control_robot(robot, x, y, image_width, has_checked, t):\n",
    "    \n",
    "    if x is not None and y is not None:\n",
    "        t = 0.1\n",
    "        center = image_width // 2\n",
    "        error = x - center\n",
    "\n",
    "        if abs(error) < 90:\n",
    "            robot.forward(0.6)\n",
    "        elif error < -50:\n",
    "            robot.forward(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.forward_left(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.left(0.5)\n",
    "        elif error > 50:\n",
    "            robot.forward(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.forward_right(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.right(0.5)\n",
    "    elif t >= 0.3:\n",
    "        robot.backward(0.2)\n",
    "        t = 0.1\n",
    "        time.sleep(0.2)\n",
    "        has_checked = False\n",
    "    elif not has_checked:\n",
    "        robot.left(0.6)\n",
    "        time.sleep(t)\n",
    "        has_checked = True\n",
    "        t += 0.05\n",
    "    elif has_checked:\n",
    "        robot.right(0.6)\n",
    "        time.sleep(t)\n",
    "        has_checked = False\n",
    "        t += 0.05\n",
    "        \n",
    "    return has_checked, t\n",
    "\n",
    " \n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Create the image widget for displaying the frame with contour\n",
    "\n",
    "    image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "    display(image_widget)\n",
    "    \n",
    "    has_checked = False\n",
    "    t = 0.1\n",
    "\n",
    "    # Initialize the robot and camera\n",
    "\n",
    "    robot = Robot()\n",
    "\n",
    "    # Define the color range for the line (e.g., yellow or blue)\n",
    "\n",
    "    lower_color = np.array([20, 100, 100])  # Lower bound of the yellow color in HSV\n",
    "    upper_color = np.array([30, 255, 255])  # Upper bound of the yellow color in HSV\n",
    "    \n",
    "#     lower_color = np.array([110, 50, 50])\n",
    "#     upper_color = np.array([160, 255, 255])\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "            # Get the current frame from the camera\n",
    "            frame = camera.value[175:,:,:]\n",
    "\n",
    "            # Detect the line's position in the frame\n",
    "            found, x, y, largest_contour = line_detection(frame, lower_color, upper_color)\n",
    "            \n",
    "            # Draw the largest contour on the frame\n",
    "            if found:\n",
    "                cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 3)\n",
    "\n",
    "            # Update the image widget with the modified frame\n",
    "            image_widget.value = bgr8_to_jpeg(frame)\n",
    "            \n",
    "            if found and has_checked:\n",
    "                has_checked = not has_checked\n",
    "            elif not found and has_checked:\n",
    "                has_checked = not has_checked\n",
    "\n",
    "            # Control the robot based on the line's position\n",
    "            has_checked = control_robot(robot, x, y, frame.shape[1], has_checked, t)\n",
    "\n",
    "            # Sleep for a while to reduce CPU usage\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "\n",
    "    finally:\n",
    "        robot.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95799a52cfd64fbebcf0f487cebe4e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='300', width='300')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from drivers import PCA9685, Motor\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "\n",
    "# Function to convert BGR image to JPEG for displaying in the widget\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "def line_detection(image, lower_color, upper_color):\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    " \n",
    "\n",
    "    if len(contours) > 0:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        moment = cv2.moments(largest_contour)\n",
    "\n",
    "        if moment[\"m00\"] != 0:\n",
    "            cx = int(moment[\"m10\"] / moment[\"m00\"])\n",
    "            cy = int(moment[\"m01\"] / moment[\"m00\"])\n",
    "            return (True, cx, cy, largest_contour)\n",
    "\n",
    "    return (False, None, None, None)\n",
    "\n",
    " \n",
    "\n",
    "def control_robot(robot, x, y, image_width, has_checked, t):\n",
    "    \n",
    "#     last_turn = False is left, if True is right\n",
    "    \n",
    "    if x is not None and y is not None:\n",
    "        t = 0.05\n",
    "        center = image_width // 2\n",
    "        error = x - center\n",
    "\n",
    "        if abs(error) < 90:\n",
    "            robot.forward(0.4)\n",
    "        elif error < -50:\n",
    "            robot.forward(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.forward_left(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.left(0.5)\n",
    "            has_checked = True\n",
    "        elif error > 50:\n",
    "            robot.forward(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.forward_right(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.right(0.5)\n",
    "            has_checked = False\n",
    "    elif t >= 0.3:\n",
    "        robot.backward(0.2)\n",
    "        t = 0.01\n",
    "        time.sleep(0.2)\n",
    "        has_checked = not has_checked\n",
    "        \n",
    "    elif not has_checked:\n",
    "        robot.left(0.7)\n",
    "        time.sleep(t)\n",
    "        has_checked = not has_checked\n",
    "        t += 0.05\n",
    "    elif has_checked:\n",
    "        robot.right(0.7)\n",
    "        time.sleep(t)\n",
    "        has_checked = not has_checked\n",
    "        t += 0.05\n",
    "        \n",
    "    return has_checked, t\n",
    "\n",
    " \n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Create the image widget for displaying the frame with contour\n",
    "\n",
    "    image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "    display(image_widget)\n",
    "    \n",
    "    has_checked = False\n",
    "    last_turn = None\n",
    "    t = 0.1\n",
    "\n",
    "    # Initialize the robot and camera\n",
    "\n",
    "    robot = Robot()\n",
    "\n",
    "    # Define the color range for the line (e.g., yellow or blue)\n",
    "\n",
    "    lower_color = np.array([20, 100, 100])  # Lower bound of the yellow color in HSV\n",
    "    upper_color = np.array([30, 255, 255])  # Upper bound of the yellow color in HSV\n",
    "    \n",
    "#     lower_color = np.array([100, 50, 50])\n",
    "#     upper_color = np.array([160, 255, 255])\n",
    "    \n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "            # Get the current frame from the camera\n",
    "            frame = camera.value[325:,:,:]\n",
    "    \n",
    "            # Detect the line's position in the frame\n",
    "            found, x, y, largest_contour = line_detection(frame, lower_color, upper_color)\n",
    "                    \n",
    "            # Draw the largest contour on the frame\n",
    "            if found:\n",
    "                cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 3)\n",
    "\n",
    "            # Update the image widget with the modified frame\n",
    "            image_widget.value = bgr8_to_jpeg(frame)\n",
    "            \n",
    "            if found and has_checked:\n",
    "                has_checked = not has_checked\n",
    "            elif not found and has_checked:\n",
    "                has_checked = not has_checked\n",
    "\n",
    "            # Control the robot based on the line's position\n",
    "            has_checked = control_robot(robot, x, y, frame.shape[1], has_checked, t)\n",
    "\n",
    "            # Sleep for a while to reduce CPU usage\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "\n",
    "    finally:\n",
    "        robot.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from drivers import PCA9685, Motor\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "\n",
    "# Function to convert BGR image to JPEG for displaying in the widget\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "# This function detects the line in the image using color thresholding and contour detection\n",
    "def line_detection(image, lower_color, upper_color):\n",
    "    # Convert image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # Create a binary mask where color of the line falls within the bounds\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If any contour is found\n",
    "    if len(contours) > 0:\n",
    "        # Find the largest contour based on area\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        # Calculate moments of the largest contour\n",
    "        moment = cv2.moments(largest_contour)\n",
    "\n",
    "        # If the contour has area (prevents divide by zero error)\n",
    "        if moment[\"m00\"] != 0:\n",
    "            # Calculate centroid of the contour\n",
    "            cx = int(moment[\"m10\"] / moment[\"m00\"])\n",
    "            cy = int(moment[\"m01\"] / moment[\"m00\"])\n",
    "            # Return flag, centroid and the contour itself\n",
    "            return (True, cx, cy, largest_contour)\n",
    "\n",
    "    # If no contour found, return False and None values\n",
    "    return (False, None, None, None)\n",
    "\n",
    "# This function controls the robot based on the position of the line\n",
    "def control_robot(robot, x, y, image_width, has_checked, t):\n",
    "    # If line is detected\n",
    "    if x is not None and y is not None:\n",
    "        # Calculate error between line's position and center of the frame\n",
    "        center = image_width // 2\n",
    "        error = x - center\n",
    "\n",
    "        # If line is close to center, move forward\n",
    "        if abs(error) < 90:\n",
    "            robot.forward(0.6)\n",
    "        # If line is to the left, turn left\n",
    "        elif error < -50:\n",
    "            robot.forward(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.forward_left(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.left(0.5)\n",
    "        # If line is to the right, turn right\n",
    "        elif error > 50:\n",
    "            robot.forward(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.forward_right(0.4)\n",
    "            time.sleep(0.02)\n",
    "            robot.right(0.5)\n",
    "    # If no line detected\n",
    "    else:\n",
    "        # Do a left-right scanning motion to try and find the line\n",
    "        if not has_checked:\n",
    "            robot.left(0.6)\n",
    "            time.sleep(t)\n",
    "            has_checked = True\n",
    "            t += 0.05\n",
    "        elif has_checked:\n",
    "            robot.right(0.6)\n",
    "            time.sleep(t)\n",
    "            has_checked = False\n",
    "            t += 0.05\n",
    "        \n",
    "    return has_checked, t\n",
    "\n",
    "# The main function where robot and camera are initialized and control loop is run\n",
    "def main():\n",
    "\n",
    "    # Create an image widget for displaying frame with contour\n",
    "    image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "    # Display the image widget in the Jupyter notebook\n",
    "    display(image_widget)\n",
    "    \n",
    "    # Initialize boolean for checking line detection and a time variable\n",
    "    has_checked = False\n",
    "    t = 0.1\n",
    "\n",
    "    # Initialize the robot and camera\n",
    "    robot = Robot()\n",
    "\n",
    "    # Define the color range for the line (Yellow)\n",
    "    lower_color1 = np.array([20, 100, 100])  # Lower bound of the yellow color in HSV\n",
    "    upper_color1 = np.array([30, 255, 255])  # Upper bound of the yellow color in HSV\n",
    "\n",
    "    # Define the color range for the line (Blue)\n",
    "    lower_color2 = np.array([110, 50, 50])  # Lower bound of the yellow color in HSV\n",
    "    upper_color2 = np.array([160, 255, 255])  # Upper bound of the yellow color in HSV\n",
    "\n",
    "    # Begin main control loop\n",
    "    try:\n",
    "        while True:\n",
    "            # Get the current frame from the camera\n",
    "            frame = camera.value[175:,:,:]\n",
    "\n",
    "            # Detect the yellow line's position in the frame \n",
    "            found1, x1, y1, largest_contour1 = line_detection(frame, lower_color1, upper_color1)\n",
    "\n",
    "            # Detect the Bue line's position in the frame \n",
    "            found2, x2, y2, largest_contour2 = line_detection(frame, lower_color2, upper_color2)\n",
    "            \n",
    "            # Checks which color has the largest contour\n",
    "            if max(largest_contour1,largest_contour2) == largest_contour1:\n",
    "                largest_contour, x, y = largest_contour1, x1, y1\n",
    "            elif max(largest_contour1,largest_contour2) == largest_contour2:\n",
    "                largest_contour, x, y = largest_contour2, x2, y2\n",
    "\n",
    "            # If a line is detected, draw the largest contour on the frame\n",
    "            if found1 and found2:\n",
    "                cv2.drawContours(frame, [largest_contour], -1, (0, 255, 0), 3)\n",
    "\n",
    "            # Update the image widget with the modified frame\n",
    "            image_widget.value = bgr8_to_jpeg(frame)\n",
    "            \n",
    "            # If line was found and has_checked is true, set has_checked to false, and vice versa\n",
    "            if found and has_checked:\n",
    "                has_checked = not has_checked\n",
    "            elif not found and has_checked:\n",
    "                has_checked = not has_checked\n",
    "\n",
    "            # Control the robot based on the line's position\n",
    "            has_checked, t = control_robot(robot, x, y, frame.shape[1], has_checked, t)\n",
    "\n",
    "            # Sleep for a while to reduce CPU usage\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    # If the control loop is interrupted, stop the robot\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        robot.stop()\n",
    "\n",
    "    # If an unhandled exception occurs, also stop the robot\n",
    "    finally:\n",
    "        robot.stop()\n",
    "\n",
    "# Run the main function if this script is run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use traitlets and widgets to display the image in Jupyter Notebook\n",
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "#use opencv to covert the depth image to RGB image for displaying purpose\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "import time\n",
    "from RobotClass import Robot\n",
    "\n",
    "#using realsense to capture the color and depth image\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    #this changing of this value will be captured by traitlets\n",
    "    color_value = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "        \n",
    "        #configure the color and depth sensor\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.configuration = rs.config()  \n",
    "        \n",
    "        #set resolution for the color camera\n",
    "        self.color_width = 640\n",
    "        self.color_height = 480\n",
    "        self.color_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.color, self.color_width, self.color_height, rs.format.bgr8, self.color_fps)\n",
    "\n",
    "        #set resolution for the depth camera\n",
    "        self.depth_width = 640\n",
    "        self.depth_height = 480\n",
    "        self.depth_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.depth, self.depth_width, self.depth_height, rs.format.z16, self.depth_fps)\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "        \n",
    "        #start the RGBD sensor\n",
    "        self.pipeline.start(self.configuration)\n",
    "        self.pipeline_started = True\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "\n",
    "        #start capture the first color image\n",
    "        color_frame = frames.get_color_frame()   \n",
    "        image = np.asanyarray(color_frame.get_data())\n",
    "        self.color_value = image\n",
    "\n",
    "        #start capture the first depth image\n",
    "        depth_frame = frames.get_depth_frame()           \n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        self.depth_value = depth_colormap   \n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            frames = self.pipeline.wait_for_frames() #receive data from RGBD sensor\n",
    "            \n",
    "            color_frame = frames.get_color_frame() #get the color image\n",
    "            image = np.asanyarray(color_frame.get_data()) #convert color image to numpy array\n",
    "            self.color_value = image #assign the numpy array image to the color_value variable \n",
    "\n",
    "            depth_frame = frames.get_depth_frame() #get the depth image           \n",
    "            depth_image = np.asanyarray(depth_frame.get_data()) #convert depth data to numpy array\n",
    "            #conver depth data to BGR image for displaying purpose\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            self.depth_value = depth_colormap #assign the color BGR image to the depth value\n",
    "    \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the position of the line in the image\n",
    "def find_line_position(image, lower_color_range, upper_color_range):\n",
    "    # Convert image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # Create a mask for the specified color range\n",
    "    mask = cv2.inRange(hsv, lower_color_range, upper_color_range)\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    line_position = None\n",
    "    max_area = 0\n",
    "    \n",
    "    # Find the contour with the largest area\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            # Calculate the centroid of the contour\n",
    "            moments = cv2.moments(contour)\n",
    "            if moments['m00'] != 0:\n",
    "                cx = int(moments['m10'] / moments['m00'])\n",
    "                line_position = cx\n",
    "    \n",
    "    return line_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make the robot follow the line\n",
    "def follow_line(robot, line_position, image_center, kp=0.01, speed=0.2):\n",
    "    if line_position is not None:\n",
    "        # Calculate the error between the line position and the image center\n",
    "        error = image_center - line_position\n",
    "        # Calculate the turn speed based on the error\n",
    "        turn_speed = error * kp\n",
    "        # Calculate the speed for each wheel\n",
    "        left_speed = speed - turn_speed\n",
    "        right_speed = speed + turn_speed\n",
    "        # Set the motor speeds\n",
    "        robot.set_motors(left_speed, right_speed, left_speed, right_speed)\n",
    "    else:\n",
    "        robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_widget(image):\n",
    "    _, encoded_image = cv2.imencode('.jpg', image)\n",
    "    image_widget.value = encoded_image.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the robot\n",
    "robot = Robot()\n",
    "\n",
    "# Initialize the camera\n",
    "camera = Camera.instance()\n",
    "\n",
    "# Set the color range for the line (yellow or blue)\n",
    "lower_color_range = np.array([20, 100, 100])  # Modify these values for the line color\n",
    "upper_color_range = np.array([30, 255, 255])  # Modify these values for the line color\n",
    "\n",
    "# Create an image widget for displaying the camera feed\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "display(image_widget)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Capture an image\n",
    "        image = camera.color_value\n",
    "\n",
    "        # Update the image widget with the current camera frame\n",
    "        update_image_widget(image)\n",
    "\n",
    "        # Find the line position\n",
    "        line_position = find_line_position(image, lower_color_range, upper_color_range)\n",
    "\n",
    "        # Make the robot follow the line\n",
    "        image_center = image.shape[1] // 2\n",
    "        follow_line(robot, line_position, image_center)\n",
    "\n",
    "        # Sleep for a while\n",
    "        sleep(0.1)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    robot.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

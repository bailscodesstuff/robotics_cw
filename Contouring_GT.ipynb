{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use traitlets and widgets to display the image in Jupyter Notebook\n",
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "#use opencv to covert the depth image to RGB image for displaying purpose\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from RobotClass import Robot\n",
    "from CameraClass import Camera\n",
    "\n",
    "#using realsense to capture the color and depth image\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    #this changing of this value will be captured by traitlets\n",
    "    value = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "        \n",
    "        #configure the color and depth sensor\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.configuration = rs.config()  \n",
    "        \n",
    "        #set resolution for the color camera\n",
    "        self.color_width = 640\n",
    "        self.color_height = 480\n",
    "        self.color_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.color, self.color_width, self.color_height, rs.format.bgr8, self.color_fps)\n",
    "\n",
    "        #set resolution for the depth camera\n",
    "        self.depth_width = 640\n",
    "        self.depth_height = 480\n",
    "        self.depth_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.depth, self.depth_width, self.depth_height, rs.format.z16, self.depth_fps)\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "        \n",
    "        #start the RGBD sensor\n",
    "        self.pipeline.start(self.configuration)\n",
    "        self.pipeline_started = True\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "\n",
    "        #start capture the first color image\n",
    "        color_frame = frames.get_color_frame()   \n",
    "        image = np.asanyarray(color_frame.get_data())\n",
    "        self.value = image\n",
    "\n",
    "        #start capture the first depth image\n",
    "        depth_frame = frames.get_depth_frame()           \n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        self.depth_value = depth_colormap   \n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            frames = self.pipeline.wait_for_frames() #receive data from RGBD sensor\n",
    "            \n",
    "            color_frame = frames.get_color_frame() #get the color image\n",
    "            image = np.asanyarray(color_frame.get_data()) #convert color image to numpy array\n",
    "            self.value = image #assign the numpy array image to the color_value variable \n",
    "\n",
    "            depth_frame = frames.get_depth_frame() #get the depth image           \n",
    "            depth_image = np.asanyarray(depth_frame.get_data()) #convert depth data to numpy array\n",
    "            #conver depth data to BGR image for displaying purpose\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            self.depth_value = depth_colormap #assign the color BGR image to the depth value\n",
    "    \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from drivers import PCA9685, Motor\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import traitlets\n",
    "\n",
    "def line_detection(image, lower_color, upper_color):\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    " \n",
    "\n",
    "    if len(contours) > 0:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        moment = cv2.moments(largest_contour)\n",
    "\n",
    "        if moment[\"m00\"] != 0:\n",
    "            cx = int(moment[\"m10\"] / moment[\"m00\"])\n",
    "            cy = int(moment[\"m01\"] / moment[\"m00\"])\n",
    "            return (True, cx, cy)\n",
    "\n",
    "    return (False, None, None)\n",
    "\n",
    " \n",
    "\n",
    "def control_robot(robot, x, y, image_width, has_checked, t):\n",
    "    \n",
    "    if x is not None and y is not None:\n",
    "        t = 0.1\n",
    "        center = image_width // 2\n",
    "        error = x - center\n",
    "\n",
    "        if abs(error) < 50:\n",
    "            robot.forward(0.6)\n",
    "        elif error < 0:\n",
    "            robot.left(0.4)\n",
    "        else:\n",
    "            robot.right(0.4)\n",
    "    elif t >= 0.3:\n",
    "        robot.backward(0.2)\n",
    "        t = 0.1\n",
    "        time.sleep(0.2)\n",
    "        has_checked = False\n",
    "    elif not has_checked:\n",
    "        robot.left(0.6)\n",
    "        time.sleep(t)\n",
    "        has_checked = True\n",
    "        t += 0.05\n",
    "    elif has_checked:\n",
    "        robot.right(0.6)\n",
    "        time.sleep(t)\n",
    "        has_checked = False\n",
    "        t += 0.05\n",
    "        \n",
    "    return has_checked, t\n",
    "\n",
    " \n",
    "\n",
    "def main():\n",
    "    \n",
    "    has_checked = False\n",
    "    t = 0.1\n",
    "\n",
    "    # Initialize the robot and camera\n",
    "\n",
    "    robot = Robot()\n",
    "\n",
    "    # Define the color range for the line (e.g., yellow or blue)\n",
    "\n",
    "    lower_color = np.array([20, 100, 100])  # Lower bound of the yellow color in HSV\n",
    "    upper_color = np.array([30, 255, 255])  # Upper bound of the yellow color in HSV\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "\n",
    "            # Get the current frame from the camera\n",
    "            frame = camera.value\n",
    "\n",
    "            # Detect the line's position in the frame\n",
    "            found, x, y = line_detection(frame, lower_color, upper_color)\n",
    "            \n",
    "            if found and has_checked:\n",
    "                has_checked = not has_checked\n",
    "            elif not found and has_checked:\n",
    "                has_checked = not has_checked\n",
    "\n",
    "            # Control the robot based on the line's position\n",
    "            has_checked = control_robot(robot, x, y, frame.shape[1], has_checked, t)\n",
    "\n",
    "            # Sleep for a while to reduce CPU usage\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "\n",
    "    finally:\n",
    "        robot.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import time\n",
    "# from drivers import PCA9685, Motor\n",
    "# from traitlets.config.configurable import SingletonConfigurable\n",
    "# import traitlets\n",
    "\n",
    "# def line_detection(image, lower_color, upper_color):\n",
    "\n",
    "#     hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "#     mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "#     contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    " \n",
    "\n",
    "#     if len(contours) > 0:\n",
    "#         largest_contour = max(contours, key=cv2.contourArea)\n",
    "#         moment = cv2.moments(largest_contour)\n",
    "\n",
    "#         if moment[\"m00\"] != 0:\n",
    "#             cx = int(moment[\"m10\"] / moment[\"m00\"])\n",
    "#             cy = int(moment[\"m01\"] / moment[\"m00\"])\n",
    "#             return (True, cx, cy)\n",
    "\n",
    "#     return (False, None, None)\n",
    "\n",
    " \n",
    "\n",
    "# def control_robot(robot, x, y, image_width, last_turn, t):\n",
    "    \n",
    "#     if x is not None and y is not None:\n",
    "#         t = 0.1\n",
    "#         center = image_width // 2\n",
    "#         error = x - center\n",
    "\n",
    "#         if abs(error) < 50:\n",
    "#             robot.forward(0.6)\n",
    "#         elif error < 0:\n",
    "#             robot.left(0.4)\n",
    "#             last_turn = \"left\"\n",
    "#         else:\n",
    "#             robot.right(0.4)\n",
    "#             last_turn = \"right\"\n",
    "#     elif t >= 0.3:\n",
    "#         robot.backward(0.2)\n",
    "#         t = 0.1\n",
    "#         time.sleep(0.2)\n",
    "#         if last_turn == 'right':\n",
    "#             last_turn = \"left\"\n",
    "#         else:\n",
    "#             last_turn = \"right\"\n",
    "#     elif last_turn == \"right\":\n",
    "#         robot.left(0.6)\n",
    "#         time.sleep(t)\n",
    "#         last_turn = \"left\"\n",
    "#         t += 0.05\n",
    "#     elif last_turn == \"left\":\n",
    "#         robot.right(0.6)\n",
    "#         time.sleep(t)\n",
    "#         last_turn = \"right\"\n",
    "#         t += 0.05\n",
    "        \n",
    "#     return last_turn, t\n",
    "\n",
    " \n",
    "\n",
    "# def main():\n",
    "    \n",
    "#     last_turn = None\n",
    "\n",
    "#     t = 0.1\n",
    "\n",
    "#     # Initialize the robot and camera\n",
    "\n",
    "#     robot = Robot()\n",
    "\n",
    "#     # Define the color range for the line (e.g., yellow or blue)\n",
    "\n",
    "#     lower_color = np.array([20, 100, 100])  # Lower bound of the yellow color in HSV\n",
    "#     upper_color = np.array([30, 255, 255])  # Upper bound of the yellow color in HSV\n",
    "\n",
    "#     try:\n",
    "#         while True:\n",
    "\n",
    "#             # Get the current frame from the camera\n",
    "#             frame = camera.value\n",
    "\n",
    "#             # Detect the line's position in the frame\n",
    "#             found, x, y = line_detection(frame, lower_color, upper_color)\n",
    "            \n",
    "# #             if found and has_checked:\n",
    "# #                 has_checked = not has_checked\n",
    "# #             elif not found and has_checked:\n",
    "# #                 has_checked = not has_checked\n",
    "\n",
    "#             # Control the robot based on the line's position\n",
    "#             last_turn = control_robot(robot, x, y, frame.shape[1], last_turn, t)\n",
    "\n",
    "#             # Sleep for a while to reduce CPU usage\n",
    "#             time.sleep(0.05)\n",
    "\n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"Interrupted\")\n",
    "\n",
    "#     finally:\n",
    "#         robot.stop()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()\n",
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
